#!/usr/bin/env Rscript
#
# Copyright 2015 Google Inc. All rights reserved.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

# Reads map files, report files, and RAPPOR parameters to run
# an EM algorithm to estimate joint distribution over two or more variables
#
# Usage:
#       $ ./analyze_assoc.R -map1 map_1.csv -map2 map_2.csv \
#                                 -reports reports.csv \
# Inputs: map1, map2, reports, params
#         see how options are parsed below for more information
# Outputs:
#         prints a table with estimated joint probability masses
#         over candidate strings
#         Ex.
#                 ssl   nossl
#         intel   0.1   0.3
#         google  0.5   0.1

##############################################################################
##############################################################################
##############################################################################
# D E P R E C A T E D
# Please use analyze_assoc_expt.R to run assoc analysis experiments 
##############################################################################
##############################################################################
##############################################################################

library("optparse")

options(stringsAsFactors = FALSE)

if(!interactive()) {
  option_list <- list(
    # Flags
    make_option(c("--map1"), default = "map_1.csv",
                help = "Hashed candidates for 1st variable"),
    make_option(c("--map2"), default = "map_2.csv",
                help = "Hashed candidates for 2nd variable"),
    make_option(c("--map3"), default = "map_3.csv",
                help = "Hashed candidates for 3rd variable"),
    make_option(c("--reports", "-r"), default = "reports.csv",
                help = "File with raw reports as <cohort, report1, report2, ...>"),
    make_option(c("--truefile", "-t"), default = "truedist.csv",
                help = "File with true distribution generated by assoc_sim.R"),
    make_option(c("--outdir", "-o"), default = ".",
                help = "File where the metrics go"),
    make_option(c("--params", "-p"), default = "params.csv",
                help = "Filename for RAPPOR parameters"),
    make_option(c("--newalg", "-a"), default = FALSE,
                help = "Flag to run new EM3 algorithm or not")
  )
  opts <- parse_args(OptionParser(option_list = option_list))
}

source("analysis/R/encode.R")
source("analysis/R/decode.R")
source("analysis/R/simulation.R")
source("analysis/R/read_input.R")
source("analysis/R/association.R")

# This function processes the maps loaded using ReadMapFile
# Association analysis requires a map object with a map
# field that has the map split into cohorts and an rmap field
# that has all the cohorts combined
# Arguments:
#       map = map object with cohorts as sparse matrix in
#             object map$map
#             This is the expected object from ReadMapFile
#       params = data field with parameters
# TODO(pseudorandom): move this functionality to ReadMapFile
ProcessMap <- function(map, params) {
  map$rmap <- map$map
  map$map <- lapply(1:params$m, function(i)
                          map$rmap[seq(from = ((i - 1) * params$k + 1),
                                   length.out = params$k),])
  map
}

main <- function(opts) {
  ptm <- proc.time()

  params <- ReadParameterFile(opts$params)
  opts_map <- list(opts$map1, opts$map2, opts$map3)
  map <- lapply(opts_map, function(o)
                  ProcessMap(ReadMapFile(o, params = params),
                             params = params))
  # Reports must be of the format
  #     cohort no, rappor bitstring 1, rappor bitstring 2
  reportsObj <- read.csv(opts$reports,
                         colClasses = c("integer", "character",
                                        "character", "character"),
                         header = FALSE)

  # Parsing reportsObj
  # ComputeDistributionEM allows for different sets of cohorts
  # for each variable. Here, both sets of cohorts are identical
  co <- as.list(reportsObj[1])[[1]]
  cohorts <- list(co, co, co)
  # Parse reports from reportObj cols 2, 3, and 4
  reports <- lapply(1:3, function(x) as.list(reportsObj[x + 1]))

  # Split strings into bit arrays (as required by assoc analysis)
  reports <- lapply(1:3, function(i) {
    # apply the following function to each of reports[[1]] and reports[[2]]
    lapply(reports[[i]][[1]], function(x) {
      # function splits strings and converts them to numeric values
      as.numeric(strsplit(x, split = "")[[1]])
    })
  })

  joint_dist <- ComputeDistributionEM(reports, cohorts, map,
                                      ignore_other = TRUE,
                                      quick = TRUE,
                                      params, marginals = NULL,
                                      estimate_var = FALSE,
                                      new_alg = opts$newalg)

  
  td <- read.csv(file = opts$truefile)
  ed <- joint_dist$orig$fit
  if(length(reports) == 3) {
    ed <- as.data.frame(ed) 
  }
  
  # We can see if chi-squared tests show different results
  # for estimated vs real distribution
  print("CHI-SQUARED")
  td_chisq <- chisq.test(td)
  ed_chisq <- chisq.test(ed)
  print(td_chisq)
  print(ed_chisq)
  print(l1d(td, ed, "L1 DISTANCE"))
  l1d_metric <- l1d(td, ed, "")
  print("JOINT_DIST$FIT")
  print(signif(ed[order(rowSums(ed)),], 4))
  td_metric <- td_chisq[1][[1]][[1]]
  ed_metric <- ed_chisq[1][[1]][[1]]
  
  print("PROC.TIME")
  time_taken <- proc.time() - ptm
  print(time_taken)
  
  metrics <- list(td_chisq = td_metric,
                  ed_chisq = ed_metric,
                  tv = l1d_metric/2,
                  time = time_taken[1],
                  dim1 = dim(ed)[[2]],
                  dim2 = dim(ed)[[1]])
  
  # Write metrics to metrics.csv
  # Report l1 distance / 2 to be consistent with histogram analysis
  filename <- file.path(opts$outdir, 'metrics.csv')
  write.csv(metrics, file = filename, row.names = FALSE)
}

# L1 distance = 1 - sum(min(df1|x, df2|x)) where
# df1|x / df2|x projects the distribution to the intersection x of the
# supports of df1 and df2
l1d <- function(df1, df2, statement = "L1 DISTANCE") {
  rowsi <- intersect(rownames(df1), rownames(df2))
  colsi <- intersect(colnames(df1), colnames(df2))
  print(statement)
  1 - sum(mapply(min, 
                 unlist(as.data.frame(df1)[rowsi, colsi], use.names = FALSE),
                 unlist(as.data.frame(df2)[rowsi, colsi], use.names = FALSE)))
}

if(!interactive()) {
  main(opts)
}
